![[hyena.assets/Pasted image 20240610195712.png]]
# 鬣(Liè)狗层次结构：迈向更大的卷积语言模型

## 摘要：
Transformer的注意力模块对于序列长度有二次成本，限制了上下文的访问量。现有的基于低秩和稀疏近似的次二次方法需要与密集注意力层相结合才能匹配 Transformer，这表现了能力上的差距。

本文提出了Hyena，一个次二次的注意力替代模块，通过交错地使用隐式参数化的**长卷积**和**数据控制门控**构建。在处理数千到数十万个标记的回归和推理任务中，Hyena在准确性上比依赖于状态空间和其他隐式和显式方法的操作符提高了超过50个百分点，与基于注意力的模型相当。

在语言建模标准数据集（WIKITEXT103和THE PILE）上为不需要密集注意力的架构设定了新的最优结果，以序列长度 2K为例，训练计算要求减少了20%。在序列长度为8K 和 64K 时，hynea运算速度是高度优化的注意力模型的两倍和 100 倍。

---

## 1.引言
大型Transformer已经在语言建模、视觉、音频、生物学和许多其他领域取得了一系列突破性进展。他的成功很大程度上依赖于缩放特性和上下文学习的出现，使其能够以上下文作为输入来推广到未见过的数据和任务。

> 缩放特性：要实现最佳计算训练，模型大小和训练词库数量应等比例缩放：模型大小每增加一倍，训练词库数量也应增加一倍。**Training Compute-Optimal Large Language Models，DeepMind**
> 上下文学习：大型语言模型表现出一定的执行上下文学习的能力，但目前尚不清楚成功的任务与训练数据中存在的内容之间的关系是什么。标准Transformer可以能够从上下文示例中学习看不见的线性函数，其性能可与最优最小二乘估计器相媲美。即使在两种形式的分布偏移下，上下文学习也是可能的：（i）在模型的训练数据和推理时提示之间，以及（ii）在推理过程中的上下文示例和查询输入之间。训练 Transformer 可以在上下文中学习更复杂的函数类——即稀疏线性函数、两层神经网络和决策树——其性能与特定于任务的学习算法相匹配或超过。**What can transformers learn in-context? a case study of simple function classes**

但它也有局限性，最值得注意的问题之一是计算成本，随着输入序列长度的增加而迅速增长。该成本与序列长度L的平方成比例增加，这对于模型可以考虑的上下文量设定了严格限制。
![[hyena.assets/Pasted image 20240618180100.png|450]]

突破二次限制是迈向深度学习的新可能性的关键步骤。

减少模型中注意力计算成本的努力主要涉及线性化、低秩和稀疏逼近的使用。这些方法在表达能力和速度之间引入了一种折衷，需要与标准的注意力层相结合才能达到Transformer的质量.

越来越多的证据表明，注意力机制在语言处理中只利用了其二次能力的一小部分。

>1. **Hungry Hungry Hippos: Towards Language Modeling with State Space Models**
>
>2. 
> 
